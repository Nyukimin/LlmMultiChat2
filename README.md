# Multi-Character LLM System

[MIT](https://opensource.org/licenses/MIT)

è¤‡æ•°ã®LLMã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼ˆãƒ«ãƒŸãƒŠ/ã‚¯ãƒ©ãƒªã‚¹/ãƒŽã‚¯ã‚¹ï¼‰ãŒã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›å¾Œã«è‡ªå¾‹çš„ã«ä¼šè©±ã‚’äº¤ã‚ã™ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡ŒåŸºç›¤ã§ã™ã€‚è¨­å®šï¼ˆYAMLï¼‰ã‚’ç·¨é›†ã™ã‚‹ã ã‘ã§ã€ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã‚„æŽ¥ç¶šå…ˆã€ä¼šè©±ãƒ«ãƒ¼ãƒ«ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã¾ã™ã€‚

## æ¦‚è¦ / ç‰¹å¾´
- **LangGraph + FastAPI + WebSocket** ã§è»½é‡æ§‹æˆï¼ˆ`docs/_index_LangGraph.md` å‚ç…§ï¼‰
- **ãƒžãƒ«ãƒLLM**ï¼ˆOllama, OpenAI ã»ã‹ï¼‰ã‚’ã‚­ãƒ£ãƒ©å˜ä½ã§é¸æŠž
- **æ¬¡è©±è€…æŒ‡å**: å¿œç­”æœ«å°¾ã® `[Next: INTERNAL_ID]`ï¼ˆã¾ãŸã¯ `{"next":"INTERNAL_ID"}`ï¼‰ã‚’è§£æžã—ã€è©±è€…ã‚’æ±ºå®š
- **ãƒ­ã‚°**: ä¼šè©±ãƒ­ã‚°ã¨æ“ä½œãƒ­ã‚°ã€‚LLMå‘¼ã³å‡ºã—ã¯ç›¸é–¢IDä»˜ã REQ/RESP/TIMEOUT/ERROR ã‚’è¨˜éŒ²
- **ä¼šè©±æ•´å½¢**: å‰ç½®ãå‰Šé™¤ + æœ€å¤§2æ–‡/160å­—ã«çŸ­ç¸®ã€‚ç©ºå¿œç­”ã‚‚ã€Œï¼ˆå¿œç­”ãªã—ï¼‰ã€ã§å¯è¦–åŒ–
- **å®‰å®šåŒ–**: LLMå‘¼ã³å‡ºã—ã«60ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€ä¿å®ˆçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ¸©åº¦ãªã©ï¼‰

## ðŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
```
.
â”œâ”€â”€ LLM/
â”‚   â”œâ”€â”€ main.py                 # FastAPIã‚¨ãƒ³ãƒˆãƒª
â”‚   â”œâ”€â”€ websocket_manager.py
â”‚   â”œâ”€â”€ conversation_loop.py    # ä¼šè©±åˆ¶å¾¡/æ•´å½¢/ãƒ«ãƒ¼ãƒ—
â”‚   â”œâ”€â”€ next_speaker_resolver.py
â”‚   â”œâ”€â”€ character_manager.py
â”‚   â”œâ”€â”€ persona_manager.py
â”‚   â”œâ”€â”€ llm_factory.py          # LLMç”Ÿæˆï¼ˆæ¸©åº¦ç­‰ã‚’æŠ‘åˆ¶ï¼‰
â”‚   â”œâ”€â”€ llm_instance_manager.py
â”‚   â”œâ”€â”€ readiness_checker.py    # èµ·å‹•æ™‚ã®Ollamaæº–å‚™
â”‚   â”œâ”€â”€ memory_manager.py       # ä¼šè©±ã‚µã‚¤ã‚¯ãƒ«è¦ç´„ã®æ°¸ç¶šåŒ–
â”‚   â”œâ”€â”€ log_manager.py
â”‚   â”œâ”€â”€ config.yaml             # æŽ¥ç¶š/ä¼šè©±ãƒ«ãƒ¼ãƒ—è¨­å®š
â”‚   â”œâ”€â”€ personas.yaml           # ãƒšãƒ«ã‚½ãƒŠ
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ logs/                   # ä¼šè©±ãƒ­ã‚°ï¼ˆgitç®¡ç†å¤–ï¼‰
â”œâ”€â”€ html/
â”‚   â”œâ”€â”€ index.html / app.js / style.css
â”œâ”€â”€ logs/                       # æ“ä½œãƒ­ã‚°ï¼ˆgitç®¡ç†å¤–ï¼‰
â”œâ”€â”€ docs/
â””â”€â”€ README.md
```

## âš™ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
1) å‰æ: Python 3.9+ã€å¿…è¦ã«å¿œã˜ã¦ [Ollama](https://ollama.com/) ãŒç¨¼åƒ

2) ä¾å­˜ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆä¸»è¦ãƒ¬ãƒ³ã‚¸ã¯ `LLM/requirements.txt` ã‚’å‚ç…§: `langgraph>=0.1.70`, `httpx`, `openai` ãªã©ï¼‰
```
cd LLM
pip install -r requirements.txt
```

3) ï¼ˆä»»æ„ï¼‰.envï¼ˆOpenAIç­‰ã‚’ä½¿ã†å ´åˆï¼‰
```
OPENAI_API_KEY="sk-..."
```

4) ãƒ¢ãƒ‡ãƒ«æº–å‚™ï¼ˆOllamaï¼‰
```
ollama pull 7shi/llm-jp-3-ezo-humanities:3.7b-instruct-q8_0
```

## ðŸ”§ è¨­å®šãƒã‚¤ãƒ³ãƒˆ
`LLM/config.yaml`
```yaml
characters:
  - name: "LUMINA"   # INTERNAL_IDï¼ˆè‹±å­—ï¼‰
    display_name: "ãƒ«ãƒŸãƒŠ"
    short_name: "ã‚‹"
    provider: "ollama"
    model: "7shi/llm-jp-3-ezo-humanities:3.7b-instruct-q8_0"
    base_url: "http://localhost:11434" # ä¾‹

  - name: "CLARIS"
    display_name: "ã‚¯ãƒ©ãƒªã‚¹"
    short_name: "ã"
    provider: "ollama"
    model: "7shi/llm-jp-3-ezo-humanities:3.7b-instruct-q8_0"

  - name: "NOX"
    display_name: "ãƒŽã‚¯ã‚¹"
    short_name: "ã®"
    provider: "ollama"
    model: "7shi/llm-jp-3-ezo-humanities:3.7b-instruct-q8_0"

logs:
  conversation_dir: "LLM/logs"
  operation_dir: "logs"

conversation:
  # ãƒ¦ãƒ¼ã‚¶ãƒ¼1å…¥åŠ›ã”ã¨ã«è‡ªå‹•ã§å›žã™æœ€å¤§ã‚¿ãƒ¼ãƒ³æ•°ï¼ˆ0ãªã‚‰è‡ªå‹•ä¼šè©±ãªã—ï¼‰
  auto_loops: 3
```

`LLM/global_rules.yaml`ï¼ˆæŠœç²‹ï¼‰
- æ—¥æœ¬èªžã§æ‰‹çŸ­ï¼ˆ2ã€œ3æ–‡ï¼‰
- æ€è€ƒ/ãƒ¡ã‚¿æƒ…å ±ç¦æ­¢
- å¿œç­”æœ«å°¾ã§ `[Next: INTERNAL_ID]`ï¼ˆã§ãã‚Œã° `{\"next\":\"INTERNAL_ID\"}` ã‚‚ï¼‰

`LLM/personas.yaml`
- ãƒ«ãƒŸãƒŠ/ã‚¯ãƒ©ãƒªã‚¹/ãƒŽã‚¯ã‚¹ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ€§ã€‚ã‚¯ãƒ©ãƒªã‚¹ã¯æŽ¨æ¸¬å›žé¿ãƒ»æ ¹æ‹ æç¤ºã‚’å¼·èª¿

## ðŸš€ èµ·å‹•
```
cd LLM
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```
ãƒ–ãƒ©ã‚¦ã‚¶: `http://127.0.0.1:8000/static/`

## ðŸ”­ ãƒ­ã‚°ã¨å¯è¦³æ¸¬æ€§
- æ“ä½œãƒ­ã‚°: `logs/operation_*.log`
  - ä¾‹: `[INFO] [LLMCall] REQ ab12cd34 -> speaker=ã‚¯ãƒ©ãƒªã‚¹, provider=...`
  - ä¾‹: `[INFO] [LLMCall] RESP ab12cd34 <- speaker=ã‚¯ãƒ©ãƒªã‚¹, chars=...`
- ä¼šè©±ãƒ­ã‚°: `LLM/logs/conversation_*.log`
- `.gitignore` ã«ã‚ˆã‚Šãƒ­ã‚°ã¯ãƒªãƒã‚¸ãƒˆãƒªã«å«ã¾ã‚Œã¾ã›ã‚“

## ã‚ˆãã‚ã‚‹è³ªå•
- å¿œç­”ãŒé•·ã™ãŽã‚‹/æœªå®Œã«è¦‹ãˆã‚‹ â†’ ã‚µãƒ¼ãƒå´ã§å‰ç½®ãå‰Šé™¤+çŸ­ç¸®ã‚’é©ç”¨ã€‚å¿…è¦ãªã‚‰ `conversation_loop.py` ã®é–¾å€¤ã‚’èª¿æ•´
- è‡ªå‹•ä¼šè©±ãŒæ­¢ã¾ã‚‹ â†’ `conversation.auto_loops` ã‚’ç¢ºèªã€‚20 ãªã©å¤§ããã™ã‚‹ã¨å·¡å›žç¶™ç¶šã—ã¾ã™
- OpenAI/Ollama ã®ç–Žé€š â†’ `OPENAI_API_KEY` ã‚„ `base_url` ã‚’ç¢ºèªã€‚Ollamaã¯ `/api/*` ã®ç”ŸRESTã‚’åˆ©ç”¨ã—ã¾ã™

## LangGraph é–¢é€£è³‡æ–™
- è¨­è¨ˆ/ç§»è¡Œ/PoC/ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã¯ `docs/_index_LangGraph.md` ã‚’å‚ç…§

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
MIT
